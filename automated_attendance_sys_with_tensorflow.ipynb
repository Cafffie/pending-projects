{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dae9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "# pip install opencv-python tensorflow face_recognition\n",
    "\n",
    "import cv2\n",
    "import face_recognition\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load images and encode faces\n",
    "def load_images_and_encode():\n",
    "    # Replace 'path_to_image' with the actual path to your dataset\n",
    "    image_of_person1 = face_recognition.load_image_file(\"path_to_image/person1.jpg\")\n",
    "    image_of_person2 = face_recognition.load_image_file(\"path_to_image/person2.jpg\")\n",
    "\n",
    "    # Encode faces\n",
    "    encoding_person1 = face_recognition.face_encodings(image_of_person1)[0]\n",
    "    encoding_person2 = face_recognition.face_encodings(image_of_person2)[0]\n",
    "\n",
    "    return [(encoding_person1, \"Person 1\"), (encoding_person2, \"Person 2\")]\n",
    "\n",
    "# Define a simple face recognition model using Keras\n",
    "def create_face_recognition_model(input_shape):\n",
    "    model = keras.Sequential([\n",
    "        layers.InputLayer(input_shape=input_shape),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(len(known_faces), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train the face recognition model\n",
    "def train_face_recognition_model(model, X_train, y_train):\n",
    "    model.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "# Recognize faces in the video stream using the trained model\n",
    "def recognize_faces_with_model(video_capture, model, known_faces):\n",
    "    while True:\n",
    "        # Capture video frame-by-frame\n",
    "        ret, frame = video_capture.read()\n",
    "\n",
    "        # Find face locations and face encodings\n",
    "        face_locations = face_recognition.face_locations(frame)\n",
    "        face_encodings = face_recognition.face_encodings(frame, face_locations)\n",
    "\n",
    "        # Loop through each face in the frame\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            # Reshape the face encoding to match the model input shape\n",
    "            face_encoding = face_encoding.reshape(1, -1)\n",
    "\n",
    "            # Predict using the trained model\n",
    "            prediction = model.predict(face_encoding)\n",
    "            predicted_index = int(tf.argmax(prediction, axis=1))\n",
    "\n",
    "            # Get the name from the known faces list\n",
    "            name = known_faces[predicted_index][1]\n",
    "\n",
    "            # Draw a rectangle and label on the frame\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, name, (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow(\"Video\", frame)\n",
    "\n",
    "        # Break the loop if 'q' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the video capture object\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def main():\n",
    "    # Load known faces and their encodings\n",
    "    known_faces = load_images_and_encode()\n",
    "\n",
    "    # Create a simple face recognition model\n",
    "    input_shape = len(known_faces[0][0])\n",
    "    model = create_face_recognition_model(input_shape)\n",
    "\n",
    "    # Prepare training data (X_train: face encodings, y_train: labels)\n",
    "    X_train = [face[0] for face in known_faces]\n",
    "    y_train = [i for i in range(len(known_faces))]\n",
    "\n",
    "    # Train the face recognition model\n",
    "    train_face_recognition_model(model, X_train, y_train)\n",
    "\n",
    "    # Open a video capture object (you can replace 0 with the video file path)\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "    # Start face recognition with the trained model\n",
    "    recognize_faces_with_model(video_capture, model, known_faces)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4e2e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e9b8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and encode faces\n",
    "def load_images_and_encode():\n",
    "    # Replace 'path_to_image' with the actual path to your dataset\n",
    "    image_of_person1 = face_recognition.load_image_file(\"path_to_image/person1.jpg\")\n",
    "    image_of_person2 = face_recognition.load_image_file(\"path_to_image/person2.jpg\")\n",
    "\n",
    "    # Encode faces\n",
    "    encoding_person1 = face_recognition.face_encodings(image_of_person1)[0]\n",
    "    encoding_person2 = face_recognition.face_encodings(image_of_person2)[0]\n",
    "\n",
    "    return [(encoding_person1, \"Person 1\"), (encoding_person2, \"Person 2\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb18aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple face recognition model using Keras\n",
    "def create_face_recognition_model(input_shape):\n",
    "    model = keras.Sequential([\n",
    "        layers.InputLayer(input_shape=input_shape),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(len(known_faces), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a556627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the face recognition model\n",
    "def train_face_recognition_model(model, X_train, y_train):\n",
    "    model.fit(X_train, y_train, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec67d84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recognize faces in the video stream using the trained model\n",
    "def recognize_faces_with_model(video_capture, model, known_faces):\n",
    "    while True:\n",
    "        # Capture video frame-by-frame\n",
    "        ret, frame = video_capture.read()\n",
    "\n",
    "        # Find face locations and face encodings\n",
    "        face_locations = face_recognition.face_locations(frame)\n",
    "        face_encodings = face_recognition.face_encodings(frame, face_locations)\n",
    "\n",
    "        # Loop through each face in the frame\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            # Reshape the face encoding to match the model input shape\n",
    "            face_encoding = face_encoding.reshape(1, -1)\n",
    "\n",
    "            # Predict using the trained model\n",
    "            prediction = model.predict(face_encoding)\n",
    "            predicted_index = int(tf.argmax(prediction, axis=1))\n",
    "\n",
    "            # Get the name from the known faces list\n",
    "            name = known_faces[predicted_index][1]\n",
    "\n",
    "            # Draw a rectangle and label on the frame\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, name, (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow(\"Video\", frame)\n",
    "\n",
    "        # Break the loop if 'q' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the video capture object\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92af59dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load known faces and their encodings\n",
    "    known_faces = load_images_and_encode()\n",
    "\n",
    "    # Create a simple face recognition model\n",
    "    input_shape = len(known_faces[0][0])\n",
    "    model = create_face_recognition_model(input_shape)\n",
    "\n",
    "    # Prepare training data (X_train: face encodings, y_train: labels)\n",
    "    X_train = [face[0] for face in known_faces]\n",
    "    y_train = [i for i in range(len(known_faces))]\n",
    "\n",
    "    # Train the face recognition model\n",
    "    train_face_recognition_model(model, X_train, y_train)\n",
    "\n",
    "    # Open a video capture object (you can replace 0 with the video file path)\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "    # Start face recognition with the trained model\n",
    "    recognize_faces_with_model(video_capture, model, known_faces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a738f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
